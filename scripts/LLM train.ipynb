{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import logging\n",
    "import numpy as np \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from functools import partial\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from torch.optim import AdamW, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be added as special tokens\n",
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "INPUT_KEY = \"Input:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "END_KEY = \"### End\"\n",
    "RESPONSE_KEY_NL = f\"{RESPONSE_KEY}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### name for model and tokenizer\n",
    "# INPUT_MODEL = \"gpt2-medium\"\n",
    "INPUT_MODEL = \"databricks/dolly-v2-3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Loading\n",
    "def load_tokenizer(pretrained_model_name_or_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
    "    # Make the pad token the same as end of string token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Add the special tokens to the tokenizer\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [END_KEY, INSTRUCTION_KEY, RESPONSE_KEY_NL, RESPONSE_KEY]}\n",
    "    )\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(pretrained_model_name_or_path, gradient_checkpoint):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path, \n",
    "        torch_dtype = torch.bfloat16,\n",
    "        use_cache = False if gradient_checkpoint else True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tokenizer(pretrained_model_name_or_path, gradient_checkpoint):\n",
    "    tokenizer = load_tokenizer(pretrained_model_name_or_path)\n",
    "    model = load_model(pretrained_model_name_or_path, gradient_checkpoint)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = get_model_tokenizer(\n",
    "    pretrained_model_name_or_path = INPUT_MODEL, \n",
    "    gradient_checkpoint = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find max length in model configuration\n",
    "conf = model.config\n",
    "max_length = getattr(model.config, \"max_position_embeddings\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training prompt that does not contain an input string.\n",
    "INTRO_BLURB = (\n",
    "    \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    ")\n",
    "\n",
    "PROMPT_NO_INPUT_FORMAT = \"\"\"{intro}\n",
    "\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "\n",
    "{response_key}\n",
    "{response}\n",
    "\n",
    "{end_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    "    response=\"{response}\",\n",
    "    end_key=END_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "# This is the prompt that is used for generating responses using an already trained model.  It ends with the response\n",
    "# key, where the job of the model is to provide the completion that follows it (i.e. the response itself).\n",
    "PROMPT_WITH_INPUT_FORMAT = \"\"\"{intro}\n",
    "\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "\n",
    "{input_key}\n",
    "{context}\n",
    "\n",
    "{response_key}\n",
    "{response}\n",
    "\n",
    "{end_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    input_key=INPUT_KEY,\n",
    "    context=\"{context}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    "    response=\"{response}\",\n",
    "    end_key=END_KEY\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/vmpletsos/.cache/huggingface/datasets/csv/default-fd5526d2de6aca6e/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset but get first 1000 examples\n",
    "# dataset = load_dataset(\"databricks/databricks-dolly-15k\")[\"train\"].select(range(1000))\n",
    "# load dataset from csv file\n",
    "dataset = load_dataset(\"csv\", data_files=\"LLM dataset train clean.csv\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = dataset['instruction']\n",
    "contexts = dataset['context']\n",
    "responses = dataset['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_LLM(rec):\n",
    "    instruction = rec[\"instruction\"]\n",
    "    response = rec[\"response\"]\n",
    "    context = rec.get(\"context\")\n",
    "    if context:\n",
    "        rec[\"text\"] = PROMPT_WITH_INPUT_FORMAT.format(\n",
    "            instruction=instruction, \n",
    "            response=response, \n",
    "            context=context\n",
    "        )\n",
    "    else:\n",
    "        rec[\"text\"] = PROMPT_NO_INPUT_FORMAT.format(\n",
    "            instruction=instruction, \n",
    "            response=response\n",
    "        )\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\vmpletsos\\.cache\\huggingface\\datasets\\csv\\default-fd5526d2de6aca6e\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-c55832f89e92ac34.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(format_for_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch, tokenizer, max_length):\n",
    "    return tokenizer(batch[\"text\"], max_length=max_length, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\vmpletsos\\.cache\\huggingface\\datasets\\csv\\default-fd5526d2de6aca6e\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-23775980201ea07a.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "        preprocessing_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"instruction\", \"context\", \"response\", \"text\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\vmpletsos\\.cache\\huggingface\\datasets\\csv\\default-fd5526d2de6aca6e\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-6bde8d0e2597e5e3.arrow\n"
     ]
    }
   ],
   "source": [
    "# Make sure we don't have any truncated records, as this would mean the end keyword is missing.\n",
    "dataset = dataset.filter(lambda rec: len(rec[\"input_ids\"]) < max_length)\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make parameters not trainable\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if not re.search(r\"28|29|30|31\", name):\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        # print(name)\n",
    "        param.requires_grad = True\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.base_model.parameters()), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorForCompletionOnlyLM(DataCollatorForLanguageModeling):\n",
    "    def torch_call(self, examples):\n",
    "        batch = super().torch_call(examples)\n",
    "\n",
    "        # The prompt ends with the response key plus a newline\n",
    "        response_token_ids = self.tokenizer.encode(RESPONSE_KEY_NL)\n",
    "        labels = batch[\"labels\"].clone()\n",
    "\n",
    "        for i in range(len(examples)):\n",
    "            response_token_ids_start_idx = None\n",
    "            for idx in np.where(batch[\"labels\"][i] == response_token_ids[0])[0]:\n",
    "                response_token_ids_start_idx = idx\n",
    "                break\n",
    "\n",
    "            if response_token_ids_start_idx is None:\n",
    "                raise RuntimeError(\n",
    "                    f'Could not find response key {response_token_ids} in token IDs {batch[\"labels\"][i]}'\n",
    "                )\n",
    "\n",
    "            response_token_ids_end_idx = response_token_ids_start_idx + 1\n",
    "\n",
    "            # loss function ignore all tokens up through the end of the response key\n",
    "            labels[i, :response_token_ids_end_idx] = -100\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForCompletionOnlyLM(tokenizer=tokenizer, mlm=False, return_tensors=\"pt\", pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_output_dir = './train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=local_output_dir,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        fp16=False,\n",
    "        bf16=True,\n",
    "        lr_scheduler_type='constant_with_warmup',\n",
    "        num_train_epochs=10,\n",
    "        deepspeed=None,\n",
    "        gradient_checkpointing=False,\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        eval_steps=10,\n",
    "        load_best_model_at_end=False,\n",
    "        report_to=None,\n",
    "        disable_tqdm=True,\n",
    "        remove_unused_columns=False,\n",
    "        warmup_steps=0,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3763, 'learning_rate': 0.0001, 'epoch': 1.0}\n",
      "{'eval_loss': 2.843667984008789, 'eval_runtime': 0.617, 'eval_samples_per_second': 16.208, 'eval_steps_per_second': 16.208, 'epoch': 1.0}\n",
      "{'loss': 1.2761, 'learning_rate': 0.0001, 'epoch': 2.0}\n",
      "{'eval_loss': 3.1915600299835205, 'eval_runtime': 0.608, 'eval_samples_per_second': 16.447, 'eval_steps_per_second': 16.447, 'epoch': 2.0}\n",
      "{'loss': 0.5351, 'learning_rate': 0.0001, 'epoch': 3.0}\n",
      "{'eval_loss': 3.556821823120117, 'eval_runtime': 0.607, 'eval_samples_per_second': 16.474, 'eval_steps_per_second': 16.474, 'epoch': 3.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1657\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1659\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1661\u001b[0m )\n\u001b[1;32m-> 1662\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1663\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1664\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1665\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1666\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1667\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1927\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1928\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1929\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1931\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1932\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1933\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1934\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1935\u001b[0m ):\n\u001b[0;32m   1936\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\trainer.py:2699\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2698\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2699\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2701\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2702\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\trainer.py:2731\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2729\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2730\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2731\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   2732\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2733\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2734\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:662\u001b[0m, in \u001b[0;36mGPTNeoXForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39mpast_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[39m    Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39m>>> prediction_logits = outputs.logits\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[39m```\"\"\"\u001b[39;00m\n\u001b[0;32m    660\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 662\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgpt_neox(\n\u001b[0;32m    663\u001b[0m     input_ids,\n\u001b[0;32m    664\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    665\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    666\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    667\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    668\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    669\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    670\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    671\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    672\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    673\u001b[0m )\n\u001b[0;32m    675\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    676\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_out(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:553\u001b[0m, in \u001b[0;36mGPTNeoXModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    545\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    546\u001b[0m         create_custom_forward(layer),\n\u001b[0;32m    547\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m         head_mask[i],\n\u001b[0;32m    551\u001b[0m     )\n\u001b[0;32m    552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     outputs \u001b[39m=\u001b[39m layer(\n\u001b[0;32m    554\u001b[0m         hidden_states,\n\u001b[0;32m    555\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    556\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    557\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    558\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    559\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    560\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    561\u001b[0m     )\n\u001b[0;32m    562\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    563\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:320\u001b[0m, in \u001b[0;36mGPTNeoXLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, head_mask, use_cache, layer_past, output_attentions)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    311\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    312\u001b[0m     hidden_states: Optional[torch\u001b[39m.\u001b[39mFloatTensor],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    318\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m ):\n\u001b[1;32m--> 320\u001b[0m     attention_layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    321\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_layernorm(hidden_states),\n\u001b[0;32m    322\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    323\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    324\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    325\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    326\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    327\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    328\u001b[0m     )\n\u001b[0;32m    329\u001b[0m     attn_output \u001b[39m=\u001b[39m attention_layer_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: attn_output, present, (attn_weights)\u001b[39;00m\n\u001b[0;32m    330\u001b[0m     outputs \u001b[39m=\u001b[39m attention_layer_outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:139\u001b[0m, in \u001b[0;36mGPTNeoXAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, head_mask, layer_past, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    137\u001b[0m     seq_len \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m layer_past[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[0;32m    138\u001b[0m cos, sin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrotary_emb(value, seq_len\u001b[39m=\u001b[39mseq_len)\n\u001b[1;32m--> 139\u001b[0m query, key \u001b[39m=\u001b[39m apply_rotary_pos_emb(query_rot, key_rot, cos, sin, position_ids)\n\u001b[0;32m    140\u001b[0m query \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((query, query_pass), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    141\u001b[0m key \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((key, key_pass), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:283\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[1;34m(q, k, cos, sin, position_ids)\u001b[0m\n\u001b[0;32m    281\u001b[0m sin \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mgather(sin\u001b[39m.\u001b[39mrepeat(gather_indices\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), \u001b[39m2\u001b[39m, gather_indices)\n\u001b[0;32m    282\u001b[0m q_embed \u001b[39m=\u001b[39m (q \u001b[39m*\u001b[39m cos) \u001b[39m+\u001b[39m (rotate_half(q) \u001b[39m*\u001b[39m sin)\n\u001b[1;32m--> 283\u001b[0m k_embed \u001b[39m=\u001b[39m (k \u001b[39m*\u001b[39m cos) \u001b[39m+\u001b[39m (rotate_half(k) \u001b[39m*\u001b[39m sin)\n\u001b[0;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[1;32mc:\\Users\\vmpletsos\\Anaconda3\\envs\\guide2\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:274\u001b[0m, in \u001b[0;36mrotate_half\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    272\u001b[0m x1 \u001b[39m=\u001b[39m x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, : x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[0;32m    273\u001b[0m x2 \u001b[39m=\u001b[39m x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m :]\n\u001b[1;32m--> 274\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((\u001b[39m-\u001b[39;49mx2, x1), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all loss and eval loss from trainer history if loss is not None\n",
    "losses = [x['loss'] for x in trainer.state.log_history if 'loss' in x.keys()]\n",
    "eval_losses = [x['eval_loss'] for x in trainer.state.log_history if 'eval_loss' in x.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.plot(eval_losses)\n",
    "plt.legend(['Train Loss', 'Eval Loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=local_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "# This is the prompt that is used for generating responses using an already trained model.  It ends with the response\n",
    "# key, where the job of the model is to provide the completion that follows it (i.e. the response itself).\n",
    "PROMPT_FOR_GENERATION_FORMAT_WITH_INPUT = \"\"\"{intro}\n",
    "\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "\n",
    "{input_key}\n",
    "{context}\n",
    "\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    input_key=INPUT_KEY,\n",
    "    context=\"{context}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_token_id(tokenizer: PreTrainedTokenizer, key: str) -> int:\n",
    "    \"\"\"Gets the token ID for a given string that has been added to the tokenizer as a special token.\n",
    "    When training, we configure the tokenizer so that the sequences like \"### Instruction:\" and \"### End\" are\n",
    "    treated specially and converted to a single, new token.  This retrieves the token ID each of these keys map to.\n",
    "    Args:\n",
    "        tokenizer (PreTrainedTokenizer): the tokenizer\n",
    "        key (str): the key to convert to a single token\n",
    "    Raises:\n",
    "        RuntimeError: if more than one ID was generated\n",
    "    Returns:\n",
    "        int: the token ID for the given key\n",
    "    \"\"\"\n",
    "    token_ids = tokenizer.encode(key)\n",
    "    if len(token_ids) > 1:\n",
    "        raise ValueError(f\"Expected only a single token for '{key}' but found {token_ids}\")\n",
    "    return token_ids[0]\n",
    "\n",
    "def preprocess(tokenizer, instruction_text, context_text=None):\n",
    "    if context_text:\n",
    "        prompt_text = PROMPT_FOR_GENERATION_FORMAT_WITH_INPUT.format(instruction=instruction_text, context=context_text)\n",
    "    else:\n",
    "        prompt_text = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction_text)\n",
    "    print(prompt_text)\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\",)\n",
    "    inputs[\"prompt_text\"] = prompt_text\n",
    "    inputs[\"instruction_text\"] = instruction_text\n",
    "    inputs[\"context_text\"] = context_text\n",
    "    return inputs\n",
    "\n",
    "def forward(model, tokenizer, model_inputs, max_length=256):\n",
    "    input_ids = model_inputs[\"input_ids\"]\n",
    "    attention_mask = model_inputs.get(\"attention_mask\", None)\n",
    "\n",
    "    if input_ids.shape[1] == 0:\n",
    "        input_ids = None\n",
    "        attention_mask = None\n",
    "        in_b = 1\n",
    "    else:\n",
    "        in_b = input_ids.shape[0]\n",
    "\n",
    "    generated_sequence = model.generate(\n",
    "        input_ids=input_ids.to(model.device),\n",
    "        attention_mask=attention_mask.to(model.device),\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    out_b = generated_sequence.shape[0]\n",
    "    generated_sequence = generated_sequence.reshape(in_b, out_b // in_b, *generated_sequence.shape[1:])\n",
    "    instruction_text = model_inputs.pop(\"instruction_text\", None)\n",
    "\n",
    "    return {\n",
    "        \"generated_sequence\": generated_sequence, \n",
    "        \"input_ids\": input_ids,\n",
    "    }\n",
    "\n",
    "\n",
    "def postprocess(tokenizer, model_outputs):\n",
    "    response_key_token_id = get_special_token_id(tokenizer, RESPONSE_KEY_NL)\n",
    "    end_key_token_id = get_special_token_id(tokenizer, END_KEY)\n",
    "    generated_sequence = model_outputs[\"generated_sequence\"][0]\n",
    "    \n",
    "    # send it to cpu\n",
    "    generated_sequence = generated_sequence.cpu()\n",
    "    generated_sequence = generated_sequence.numpy().tolist()\n",
    "    records = []\n",
    "\n",
    "    for sequence in generated_sequence:\n",
    "        decoded = None\n",
    "\n",
    "        try:\n",
    "            response_pos = sequence.index(response_key_token_id)\n",
    "        except ValueError:\n",
    "            print(f\"Could not find response key {response_key_token_id} in: {sequence}\")\n",
    "            response_pos = None\n",
    "\n",
    "        if response_pos:\n",
    "            try:\n",
    "                end_pos = sequence.index(end_key_token_id)\n",
    "            except ValueError:\n",
    "                print(\"Could not find end key, the output is truncated!\")\n",
    "                end_pos = None\n",
    "            decoded = tokenizer.decode(sequence[response_pos + 1 : end_pos], skip_special_tokens=True).strip()\n",
    "            \n",
    "        if not decoded:\n",
    "            # Otherwise we'll decode everything and use a regex to find the response and end.\n",
    "\n",
    "            fully_decoded = tokenizer.decode(sequence)\n",
    "            # The response appears after \"### Response:\".  The model has been trained to append \"### End\" at the\n",
    "            # end.\n",
    "            m = re.search(r\"#+\\s*Response:\\s*(.+?)#+\\s*End\", fully_decoded, flags=re.DOTALL)\n",
    "            if m:\n",
    "                decoded = m.group(1).strip()\n",
    "            else:\n",
    "                # The model might not generate the \"### End\" sequence before reaching the max tokens.  In this case,\n",
    "                # return everything after \"### Response:\".\n",
    "                m = re.search(r\"#+\\s*Response:\\s*(.+)\", fully_decoded, flags=re.DOTALL)\n",
    "                if m:\n",
    "                    decoded = m.group(1).strip()\n",
    "                else:\n",
    "                    print(f\"Failed to find response in:\\n{fully_decoded}\")\n",
    "            \n",
    "            \n",
    "        rec = {\"generated_text\": decoded}\n",
    "        records.append(rec)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "How to remove rust stains from corroded connectors?\n",
      "\n",
      "### Response:\n",
      "\n",
      "LLM response:  The corrosion of copper connectors is usually caused by saltwater, rust and other corrosive liquids. The corrosion will gradually eat away the copper surface, and the copper surface is very soft, so the rust stains are very difficult to be removed.\n",
      "\n",
      "The first step is to use a corrosion inhibitor to protect the copper connectors, and the corrosion inhibitor can be sprayed on the corroded copper connectors, or it can be dissolved in the corrosion inhibitor tank.\n",
      "\n",
      "The second step is to use a copper cleaning solution to clean the corroded copper connectors, and the cleaning solution can be sprayed on the corroded copper connectors, or it can be poured into the copper cleaning tank.\n",
      "\n",
      "The third step is to use a chemical etching solution to remove the rust stains, and the chemical etching solution can be sprayed on the corroded copper connectors, or it can be poured into the chemical etching tank.\n",
      "\n",
      "The fourth step is to use a laser to remove the rust stains, and the laser can be sprayed on the corroded copper connectors, or it can be poured into the laser tank.\n",
      "Actual response:  Removing rust stains from corroded connectors is achieved by a neutralized thioglycolic acid solution\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "text = instructions[i]\n",
    "context = contexts[i]\n",
    "actual_response = responses[i]\n",
    "pre_process_result = preprocess(tokenizer, text, context)\n",
    "model_result = forward(model, tokenizer, pre_process_result)\n",
    "final_output = postprocess(tokenizer, model_result);\n",
    "print('LLM response: ', final_output[0]['generated_text'])\n",
    "print('Actual response: ', actual_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
