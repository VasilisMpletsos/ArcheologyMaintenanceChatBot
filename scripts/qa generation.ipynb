{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d30619f4-5b79-486e-9e65-38907fbfd03f",
   "metadata": {},
   "source": [
    "# Try Train a T5 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c59e783-6f82-45f4-bb65-ef656564eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14959db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_passages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a227c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"voidful/context-only-question-generator\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"voidful/context-only-question-generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66fb9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a4fa1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['passages'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddc058fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 1/672\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmpletsos\\Anaconda3\\envs\\guide\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 672/672\r"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "context = []\n",
    "total_texts = len(texts)\n",
    "for i, text in enumerate(texts):\n",
    "    # print progress\n",
    "    print(f'Checked {i+1}/{total_texts}', end='\\r')\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    input_ids = input_ids.to('cuda');\n",
    "    outputs = model.generate(input_ids)\n",
    "    questions.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    context.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c2c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['questions'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8acbdeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_passages_with_questions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
